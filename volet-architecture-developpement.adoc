= Volet développement
:sectnumlevels: 4
:toclevels: 4
:sectnums: 4
:toc: left
:icons: font
:toc-title: Sommaire

Dernière modification : {docdate}

== Introduction

Ceci est le point de vue développement de l’application. Il décrit le code à produire et comment l'écrire.

Les autres volets du dossier sont accessibles link:./README.adoc[d'ici].

== Non statué

=== Points soumis à étude complémentaire

.Points soumis à étude complémentaire
[cols="e,e,e,e,e"]
|====
|ID|Détail|Statut|Porteur du sujet  | Échéance

|ED1
|Le choix Gatsby JS ou Next JS pour le frontend est encore soumis à étude. Ceci n’impacte pas la partie back des services REST et GQL
|EN_COURS
|Equipe méthodes et outils
|AVANT Juin 2021

|====


=== Hypothèses

.Hypothèses
[cols="1e,4e"]
|====
|ID|Détail

|HD1
|Même si ce point n’est pas encore totalement validé, l’application nécessitera la mise en place de tests end to end.
|====

== Contraintes

=== Contraintes réseau
* La couverture de code devra être d'au moins 90%.
* L'équipe Front-End utilisera des licences webstorm pour faciliter le développement des tests unitaires.
* La téchnologie de tests unitaires sera la librairie Testing Library accompagné du moteur de test Jest
* L'application sera construite, testée et déployée en continu à chaque push via la plateforme Gitlab-ci
* Les normes et seuils de qualité de code applicables
* Les composants de la partie front-end seront développer en toute isolation a l'aide de la librarie Storybook.

== Exigences non fonctionnelles

=== Accessibilité

L'application ne pourra pas être accessible aux non/mal voyants ou malentendants.

=== Ergonomie

==== Charte ergonomique
A definir par les gérants du projet Cassiopée

==== Spécificités sur les widgets
Les tableaux des produits et articles blog côté panel administrateur devront être triables suivant plusieurs colonnes.

==== Polices de caractère
Roboto, simple et efficace

==== Site Web adaptatif

L'application sera complétement résponsible. Des tests devront démonter que le contenu du site dépend du support utiliser pour acceder a l'application (mobile, tablette, desktop).

==== Progressive Web Apps (PWA)

L'application Cassiopee sera totalement PWA. Des tests devront démonter que le site continuer à fonctionner sans réseau et que les pages se chargent en moins de 5 secs en 4G.


==== Navigateurs supportés

L’application Z vise le public le plus large et doté de systèmes raisonnablement anciens et devra donc supporter : Firefox 6+, Chrome 8+, Opera 8+, IE 10, Edge.

==== Internationalisation (i18n)

L’IHM X sera traduite en 25 langues dont certaines langues asiatiques et l’arabe.

Les formats de dates et autres champs de saisie devront être parfaitement localisés pour un confort maximal de l’utilisateur.

==== Mode déconnecté

L'application mobile sera en mode PWA, entièrement écrite en HTML5 avec local storage pour stocker les données de la journée dans le navigateur.

=== Exigences de SEO

L'application devra être développer avec la technologie JamStack ( gatsby JS ou Next JS), dans le but de fournir le meilleur référencement possible.

== Architecture cible

=== Pile logicielle

==== Filière technique retenue

Utilisation de Reacts.js à titre expérimental au sein de l'organisation.

==== Composants logiciels

====

.pile logicielle
[cols="1e,4e,1e"]
|====
|Librairie|Rôle|Version

|React JS
|Framework JS de présentation
|17.0.2

|====
====

=== Performances

IMPORTANT: Voir les exigences MOA dans le link:./volet-architecture-dimensionnement.adoc[volet dimmensionnement].

Coté Frontend :

* Limiter la complexité des CSS (sélecteurs ou fonctions en particulier)
* Utiliser un profiler (comme celui de Chrome)
* Privilégier les appels asynchrones

Coté Backend :

* S'assurer que la pagination serveur va bien jusqu'à la base de donnée (`LIMIT`, `OFFSET`).
* Ne pas mettre en place de contraintes inutiles en base de données.
* Limiter le nombre de jointures et les relations many-to-many.
* Dans des cas de grosses volumétries, étudier les solutions de partitionnement de tables.
* Ne pas oublier d'ajouter tous les index nécessaires, utiliser l'analyse du plan d'exécution pour vérifier qu'il n'y a pas de full scans.
* Attention aux fonctions SQL qui 'cassent' les index (comme  `UPPER()`). Privilégier les traitements coté code backend si possible.
* Activer les logs de requêtes (exemple Hibernate : `org.hibernate.SQL=DEBUG`,`-Dhibernate.generate_statistics=true`) et vérifier les equêtes SQL et leur nombre (pour détecter en particulier le problème du https://stackoverflow.com/questions/97197/what-is-the-n1-selects-problem-in-orm-object-relational-mapping[SELECT N+1], très courant).
* Disposer même sur poste de travail d'un jeu de donnée minimal (une centaine d'enregistrement).
* Vérifier avec un profiler (comme JVisualVM en Java) la consommation mémoire pour détecter les fuites ou les surconsommations.
* Vérifier qu'il n'y a pas de fuite de threads ou de deadlocks en comptant le nombre de threads actifs.
* Stresser les API _a minima_ (avec des injecteurs comme Jmeter ou K6) et via une rampe progressive.
* Traquer les IO (des millions de fois plus lents que des accès mémoire).
* ...

Frontend et backend :

* Toute ressource (taille de chaine, nombre d'appel sur une durée, ...) doit systématiquement être bornée par une limite (pas d'open bar).
* Vérifier que la taille des requêtes HTTP reste en dessous de quelques dizaines de Kio (hors GET sur fichiers). Utiliser la <<Tri et Pagination,pagination cliente et serveur>>.
* Traquer le bavardage réseau : grouper les requêtes quand possible (il faut trouver un compromis avec la règle précédente). S'aider de la règle ‘S’ de SOLID (Segregation Interface).
* Prévoir des endpoints multivalués (exemple: `GET /personnes?list=id1,id2,...`) pour récupérer plusieurs éléments à la fois
(doit se concrétiser par un seul `SELECT WHERE .. IN` dans la requête finale, pas une boucle dans le code !)



WARNING: Ne pas tomber à l'inverse dans l'optimisation prématurée "source de tous les problèmes" selon Donald Knuth. Ecrire le code le plus simple possible et suivre un bon design, ne l'optimiser qu’ensuite.
N'optimiser que si cela vaut le coût (loi de Pareto). Commencer par les optimisations les plus significatives et ne pas perdre son temps à grappiller des microsecondes voire nanosecondes.


=== Spécificités d’usine logicielle

Les jobs GITLAB produiront le logiciel sous forme de containers Docker si  tous les TU sont passants. Les tests d'intégration seront ensuite exécutés sur ce container. Si tous les tests d’intégration et BDD sont passants, l'image Docker est releasée dans Nexus.

=== Normes de développement et qualimétrie

Les langues utilisées pour le code seront le français pour les termes fonctionnels (il est impératif d'utiliser les termes métiers comme préconisé par le DDD) et l'anglais pour les termes techniques génériques.

=== Spécificités des tests

* ce projet sera couvert en plus des TU et tests d’intégration car des tests d'acceptance BDD (Behavioral Driven Development) en technologie JBehave + Serenity.


* ce projet sera développé en TDD (Test Driven Dvelopement)
====

Types de tests

.Types de tests
[cols='2s,1,1,1,1,4a']
|====
|Type de test | Temps à investir | Manuel ou automatisé ? | Type de module ciblé | Taux de Couverture visée | Détail

|TU
|Très élevé
|Automatisé
|Backend et Frontend
|env. 90%
|Format TDD : spécifications de comportements des classes et méthodes

|Spécifications exécutables
|Très élevé
|Automatisé
|Api
|env. 100% pour les classes du domaine
|Mode bouchonné.

|Tests de contrats
|Faible
|Automatisé
|Liens UI/API
|env. 100% du code appelant coté UI et des contrôleurs Spring coté API
|Teste la non régression des échanges lors de l'appel des opérations des API REST (principe CDC=Consumer-Driven Contract) via les outils Pact et pact-react-consumer.

|Tests d'architecture
|Très faible
|Automatisé
|API et batchs
|N/A, 100% du code est validé par l'outil
|En particulier, ces tests simples à écrire vérifieront le respect des règles de l'architecture hexagonale. Utilisation du framework de test ArchUnit.

|TI (tests d'intégration)
|Faible
|Automatisé
|Composants appelant des systèmes externes (bases de données, API...)
|50 à 60%
|Chaque TI ne doit tester qu'un seul système externe à la fois

|E2E (tests bout en bout)
|Faible
|Automatisé
|UI
|30%, cas nominaux (happy path)
|Ecrits en Cypress. Ils seront limités à un rôle de smoke tests (détection de problèmes grossiers). Ces tests ne seront pas bouchonnés mais seront effectués sur chaîne de liaison instanciée de bout en bout. Pour éviter le travail inutile, ces tests seront faits au niveau de features entières, pas forcément à chaque sprint. Ces tests feront office également de tests système puisqu'ils solliciteront un maximum de modules débouchonnés.

|Tests de performance
|Faible (hors campagnes de performance dédiées)
|Automatisé
|API critiques
|20%
|Possiblement automatisés en CI en DEV mais également lancé manuellement par les développeurs

|Tests d'accessibilité
|Moyenne
|Automatisé + manuel
|UI
|50%
|Tests Axe-Core lancés en CI à compléter d'un audit manuel

|Tests de sécurité
|Moyenne
|Manuel
|Tous
|Faible, uniquement sur les fonctions sensibles
|Audit à prévoir

|Tests système
|Faible
|Manuels
|UI et batchs
|10%
|Tests menés par l'équipe de développement couvrant des scénarios fonctionnels complets. Le but
est ici de tester le fonctionnement de l'ensemble des modules (ce qui n'est pas automatisable) et de
détecter un maximum de bugs avant les tests d'UAT.

|Tests UAT (acceptance)
|Moyenne
|Manuels
|UI, batchs lancé à la main
|de 30% à 80% selon le nombre de scénarios prévus
|Tests menés en recette par la MOA sur environnement non bouchonné avec des cahiers de tests. Tests d'acceptance de bout n bout (on suit un cahier de tests avec les cas nominaux), Tests exploratoires (on tente toutes les combinatoires possibles avec un guidage minimal dans le cahier de test)
|====
====

=== Éco-conception

* Le processus gulp de construction de l'application appliquera une réduction de taille des images via le plugin imagemin-pngcrush.
* Des tests de robustesse courant sur plusieurs jours seront effectués sur l’application mobile après chaque optimisation pour évaluer la consommation énergétique de l'application.
* Les campagnes de performance intégreront une analyse fine de la consommation de bande passante et en cycles CPU même si les exigences en temps de réponses sont couvertes, ceci pour identifier des optimisations permettant de répondre aux exigences d'éco-conception si elles ne sont pas atteintes.

==== Gestion des transactions
Nos ressources étant transactionnelles (services REST/GQL), il est autoriser d'appeler deux services en mise à jour de façon synchrone.

==== Gestion des erreurs
Les erreurs techniques (imprévues) comme le timeout à un appel de service REST sont catchées au plus haut niveau de l'application (via un ErrorHandler). Toutes ses informations sont loguées avec la stack-trace complète mais l'appelant ne doit recupérer que le code erreur générique XYZ sans la stack-trace (pour raison de sécurité).

=== Gestion de la configuration

La configuration sera injectée au lancement (non modifiable à chaud) via des variables d'environnements fournies dans le décripteur de déploiement Kubernetes.

=== Politique de gestion des branches

* La politique générale adoptée est la https://trunkbaseddevelopment.com/[TBD] (Trunk-Based Development)
* La branche principale est `develop`. Il s'agit d'une branche protégée vers laquelle il n'est pas possible pousser de commits.
* Tout commit devra faire l'objet d'une Merge Request avant intégration dans `develop`. Les critères de qualité (évalués de façon automatique lors de l'intégration continue) devront être atteints pour que le commit soit intégré.
* Chaque fonctionnalité, refactoring significatif ou bugfix sera donc réalisé sur une branche topic dédiée.
* Une branche de maintenance sera tirée sur chaque tag de version x.y. Seuls les bugfixs seront mergés dans les branches de maintenance depuis `develop` via des `cherry-pick`.

=== Versioning

* D'une façon générale, toute ressource non dérivée (source, outil, script de ci-cd, template, DDL de base de données, ...) doit être versionnée.
* Les modules seront versionnés suivant la numérotation `x.y.z` (`<majeur).<évolution>.<fix>`)
* Les librairies seront versionnées suivant la même numérotation que les modules mais la valeur `x` sera incrémentée lors de toute montée de version cassant la compatibilité ascendante (principe du Semantic Versioning).
* La version logique globale du projet sera : `<lot>.<no sprint>.<déploiement>`

=== Gestion de la concurrence

Tous les controllers seront en scope singleton et ne doivent donc en aucun cas stocker d'état dans leurs attributs pour éviter des race conditions.


=== Encodage

Le seul encodage autorisé dans tous les modules et composants techniques est l'UTF-8. L'utilisation de l'ISO-8859-1, CP-1252 ou de tout autre encodage est formellement proscrit. Ceci comprend le paramétrage des serveurs d'application (Node, Tomcat...), des sources, des bases de données et des fichiers.

=== Fuseaux horaires

Les dates et date-heures seront stockées en base de données comme epoch millis au format entier long. Dans le cas des dates, on stockera l'epoch millis à 12:00 UTC (et pas 00:00, trop proche du jour précédent, risque de bug).

=== Gestion des logs

NOTE: Les aspects d'infrastructure de logs sont détaillés dans link:./volet-architecture-infrastructure.adoc#_logs[le volet infrastructure].

==== Règles générales

* Ne pas laisser de logs de développement dans le code (exemple : `console.log("entrée dans méthode x")` ou `e.printStackTrace()`)
* Penser à utiliser des chaînes de caractère discriminantes (exemple : code erreur) pour faciliter le filtrage dans l'outil de recherche de logs.
* Toujours fournir des identifiants d'entités permettant de retrouver l'objet concerné
* Utiliser des identifiant de corrélation entre tiers (exemple : id de traitement générée coté client en JS, passée au serveur)
* Eviter les calculs coûteux (exemple: beaucoup de concaténations) et utiliser des blocs conditionnels (exemple en JavaScript :
```java
if (isDebugEnabled){
   console.log(a+b+c)
}
```

==== Niveaux et quantité de logs

====

.Niveaux logs
[cols='1,3,1,1']
|====
|Niveau de gravité |Contexte d'utilisation | Volume indicatif | Environnent

|DEBUG
|En environnement de développement, il permet d'afficher les valeurs de variables, E/S de méthodes etc..
|Max quelques Mio / minute
|DEV, Recette. Interdit en PROD sauf demande expresse du projet

|INFO
|Début/fin d'un batch ou d'un appel, chargement d'une nouvelle propriété. Peut être utilisé sous forme condensée pour les appels de service (logging d'un appel et de son contexte). C'est le niveau de prolixité utilisé pour la métrologie.
|Max 10 logs / sec, quelques Kio / minute
|Tous

|WARN
|Tous les messages d'avertissement sur les informations fonctionnelles inattendues
|Pas de limites mais ne pas en abuser et y positionner un maximum de détail de contexte
|Tous

|ERROR
|Toutes les erreurs qui n'empêchent pas à l'application de fonctionner.
|Pas de limites. Positionner un maximum de détail de contexte
|Tous

|FATAL
|Toutes les erreurs bloquantes pour l'application (problème d'accès BDD, HTTP  404 ou 500). Positionner un maximum de détail de contexte. Penser à bien logger ces erreurs sur un appender console au cas où l'écriture sur FS serait impossible (disque plein). Penser que lors d'une erreur fatale, l'écriture même du log est sujette à caution (par exemple en cas de dépassement mémoire).
|Pas de limites.
|Tous
|====

====

=== Provisionning et mises à jour des données
Nous utiliserons LiquiBase embarqué dans les war pour créer et mettre à jour les DDL de la base. Il n'y aura donc pas de scripts SQL à lancer, les requêtes nécessaires seront effectuées directement par l'application lors de son démarrage.